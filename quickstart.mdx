---
title: "Quickstart"
description: "Get up and running with varg in 5 minutes"
---

## Prerequisites

- [Bun](https://bun.sh) runtime (recommended) or Node.js 18+
- API key from [fal.ai](https://fal.ai/dashboard/keys) (required)

## Installation

<Tabs>
  <Tab title="Bun (recommended)">
    ```bash
    bun install vargai ai
    ```
  </Tab>
  <Tab title="npm">
    ```bash
    npm install vargai ai
    ```
  </Tab>
</Tabs>

## API Keys Setup

Create a `.env` file in your project root:

```bash
# Required - Image and video generation
FAL_KEY=fal_xxx

# Optional - Voice and music
ELEVENLABS_API_KEY=xxx

# Optional - Character images with styles
HIGGSFIELD_API_KEY=hf_xxx
HIGGSFIELD_SECRET=secret_xxx

# Optional - Sora video generation
OPENAI_API_KEY=sk_xxx

# Optional - Background removal
REPLICATE_API_TOKEN=r8_xxx
```

<AccordionGroup>
  <Accordion title="Get FAL_KEY (required)">
    1. Go to [fal.ai/dashboard/keys](https://fal.ai/dashboard/keys)
    2. Create account or sign in
    3. Generate new API key
    4. Copy key starting with `fal_`
  </Accordion>
  <Accordion title="Get ELEVENLABS_API_KEY (for voice/music)">
    1. Go to [elevenlabs.io/app/settings/api-keys](https://elevenlabs.io/app/settings/api-keys)
    2. Create account or sign in
    3. Generate new API key
  </Accordion>
</AccordionGroup>

## Your First Video

Create `hello.tsx`:

```tsx
import { render, Render, Clip, Image, Video } from "vargai/react";
import { fal } from "vargai/ai";

// Generate a character image
const character = Image({
  prompt: "cute kawaii fluffy orange cat character, round body, big eyes, Pixar style",
  model: fal.imageModel("flux-schnell"),
  aspectRatio: "9:16",
});

// Render the video
await render(
  <Render width={1080} height={1920}>
    <Clip duration={3}>
      <Video
        prompt={{
          text: "character waves hello enthusiastically, bounces up and down",
          images: [character],
        }}
        model={fal.videoModel("kling-v2.5")}
      />
    </Clip>
  </Render>,
  { output: "output/hello.mp4" }
);

console.log("Video saved to output/hello.mp4");
```

Run it:

```bash
bun run hello.tsx
```

<Info>
First run takes 1-2 minutes (AI generation). Subsequent runs with same props are instant (cached).
</Info>

## Add Music

With `ELEVENLABS_API_KEY` set:

```tsx
import { render, Render, Clip, Image, Video, Music } from "vargai/react";
import { fal, elevenlabs } from "vargai/ai";

const character = Image({
  prompt: "cute kawaii cat character, Pixar style",
  aspectRatio: "9:16",
});

await render(
  <Render width={1080} height={1920}>
    {/* Background music for entire video */}
    <Music 
      prompt="upbeat happy electronic music, cheerful vibes" 
      model={elevenlabs.musicModel()} 
      volume={0.3}
    />
    
    <Clip duration={3}>
      <Video
        prompt={{ text: "cat dancing happily", images: [character] }}
        model={fal.videoModel("kling-v2.5")}
      />
    </Clip>
  </Render>,
  { output: "output/dancing-cat.mp4" }
);
```

## Add Voiceover

```tsx
import { render, Render, Clip, Image, Video, Speech, Captions } from "vargai/react";
import { fal, elevenlabs } from "vargai/ai";

const character = Image({
  prompt: "friendly robot character, blue metallic, expressive eyes",
  aspectRatio: "9:16",
});

// Generate voiceover
const voiceover = Speech({
  model: elevenlabs.speechModel("eleven_multilingual_v2"),
  voice: "adam",
  children: "Hello! I'm your AI assistant. Let me show you something cool!",
});

await render(
  <Render width={1080} height={1920}>
    <Clip duration={5}>
      <Video
        prompt={{ text: "robot talking, subtle head movements", images: [character] }}
        model={fal.videoModel("kling-v2.5")}
      />
    </Clip>
    
    {/* Auto-generated captions synced to voiceover */}
    <Captions src={voiceover} style="tiktok" color="#ffffff" />
  </Render>,
  { output: "output/talking-robot.mp4" }
);
```

## CLI Usage

varg also includes a CLI for quick operations:

```bash
# Generate single image
varg run image --prompt "sunset over mountains"

# Generate video from text
varg run video --prompt "ocean waves crashing" --duration 5

# Generate voice
varg run voice --text "Hello world" --voice rachel

# List all available actions
varg list

# Open visual studio
varg studio
```

## Project Structure

Recommended project layout:

```
my-video-project/
├── .env              # API keys
├── package.json
├── media/            # Input assets (images, audio)
├── output/           # Generated videos
└── videos/
    ├── intro.tsx
    ├── episode-1.tsx
    └── outro.tsx
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Components Reference" icon="puzzle-piece" href="/sdk/components">
    Learn all available components and their props
  </Card>
  <Card title="AI Models" icon="microchip" href="/sdk/models">
    Explore supported image, video, and audio models
  </Card>
  <Card title="Templates" icon="clone" href="/templates">
    Copy-paste examples for common video types
  </Card>
  <Card title="Gateway API" icon="server" href="/api">
    Use the REST API for server-side generation
  </Card>
</CardGroup>
